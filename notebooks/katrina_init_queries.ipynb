{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d65c30-0ae9-4ef1-8203-5a9eb085538a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from conneg_functions import execute_to_df, generate_sparql\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import textwrap\n",
    "from IPython.core.display import HTML\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# disabel if using labnotebook , for normal notebook enable for interactive plots\n",
    "#%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed504c2f-55ba-472c-939a-52b955ccc304",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the first 3store, it will be the logsheet data only\n",
    "\n",
    "#Give me the list of observatories: their names, country, location (lat, long and mrgid), and any habitat info\n",
    "\n",
    "#For each observatory now, give me the names, the number of sampling events for water and sediment and the overall date coverage, and the number of samples taken\n",
    "\n",
    "#For a named observatory (so I input the name), give me the number and percentage of missing information in the mandatory fields, per event (not per sample!). NA is “missing information, by the way so don’t throw them out. Plot or tabulate this per mandatory field name (as given in the logsheets)\n",
    "\n",
    "#And also the summary of the %coverage in the mandatory fields for the sampling tab (that is, the sampling tab of the googlesheet) and of the measured tab separately. do not throw out the NAs here.\n",
    "\n",
    "#For the mandatory measurements, give me the mean and mean deviation, as well as max and min values, for a named observatory (so I input the name), summed over all sampling events and over all water events separately (plots could be side-by-side). Give me this following the BODC names but then also output a list of BODC vs googlesheet names so I can read that off. Throw out the NAs here\n",
    "\n",
    "#Over all observatories, list the SOPs that were used and how many times each was used (I want to see which are the popular ones). \n",
    "\n",
    "#Over all the observatories, list the samp_collect_devices used and the number of events (not samples) each was used for (I want to see how many different ones there are). Here you can throw out the NAs before reporting. \n",
    "\n",
    "#For each observatory, how many samples for water and for sediment separately have been shipped to HQ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cace55df-c49b-4fb1-b6e9-17ac71eb3a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Give me the list of observatories: their names, country, location (lat, long and mrgid), and any habitat info\n",
    "\n",
    "# tried to get info for the observatories first by\n",
    "#select * where { \n",
    "#\t?s ?p <https://data.emobon.embrc.eu/ns/core#Observatory> .\n",
    "#}\n",
    "\n",
    "# some triples were found none lead to data \n",
    "\n",
    "#then tried \n",
    "\n",
    "#select * where { \n",
    "#\t?s <https://data.emobon.embrc.eu/ns/sampling#linkedToObservatory> ?o .\n",
    "#}\n",
    "\n",
    "#no triples found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866ecbf8-f5c4-40a7-b53c-838e067d0bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
